{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMsb6czehFZR"
   },
   "source": [
    "# DBSCAN\n",
    "\n",
    "Este algoritmo funciona en base a la distribución dimensional de los puntos de entrada, como el resto de métodos que hemos visto hasta ahora. En este caso, el algoritmo agrupa los puntos de entrada dependiendo de la densidad espacial de los mismos.\n",
    "\n",
    "En concreto, los pasos que sigue el algoritmo son los siguientes:\n",
    "\n",
    "1. Se selecciona un punto del conjunto de datos de entrada y se determinan todos los puntos que se encuentren en un radio de distancia menor a $\\varepsilon$.\n",
    "2. Si existen al menos $minPoints$ dentro de dicho radio se marca como **punto núcleo** y se define un clúster.\n",
    "3. Se analizan todos los puntos del cluster comprobando cuántos puntos tienen en un radio de distancia menor a $\\varepsilon$. Si tienen al menos $minPoints$, se anotan como **puntos núcleo** y se expande el clúster. En caso contrario, el punto pertenecerá al clúster, pero no lo expandirá.\n",
    "4. Se repite el proceso con los nuevos puntos que expandieron el clúster hasta que no haya nuevos puntos.\n",
    "5. Si quedan puntos del conjunto de datos sin analizar, se reinicia el algoritmo en cualquiera de ellos creando un nuevo clúster.\n",
    "6. Si un punto no tiene ningún otro punto a una distancia menor de $\\varepsilon$, se considera ruido o *outlier*.\n",
    "\n",
    "Por tanto tenemos tres hiper-parámetros:\n",
    "\n",
    "- $\\varepsilon$ (`eps`) para determinar el radio de similitud\n",
    "- $minPoints$ para determinar cuántos puntos en su vecindad hacen a otro puntos convertirse en núcleo\n",
    "- la función de similitud de los puntos\n",
    "\n",
    "La siguiente imagen, [extraída de Wikpedia](https://es.wikipedia.org/wiki/DBSCAN), ilustra el proceso. Los puntos marcados como A son puntos núcleo. Los puntos B y C son densamente alcanzables desde A y densamente conectados con A, y pertenecen al mismo clúster. El punto N es un punto ruidoso que no es núcleo ni densamente alcanzable.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/1920px-DBSCAN-Illustration.svg.png\" width=600>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWdkEwRPQ_Hh"
   },
   "source": [
    "Una de las grandes ventajas de DBSCAN es que permite trabajar muy bien con conjuntos de datos que no son separables linealmente. Al basar la construcción de los clústers en el concepto de cercanía (i.e. vecindarios), la topología de cada clúster estará condicionada a la disposición de los puntos en el espacio de búsqueda.\n",
    "\n",
    "Veamos su funcionamiento en diferentes conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:17.378941Z",
     "start_time": "2021-11-02T10:03:17.365365Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_dbscan (X, eps, min_samples):\n",
    "\n",
    "  min = np.amin(X, axis=0)\n",
    "  max = np.amax(X, axis=0)\n",
    "\n",
    "  diff = max - min\n",
    "\n",
    "  min = min - 0.1 * diff\n",
    "  max = max + 0.1 * diff\n",
    "\n",
    "  fig, axs = plt.subplots(len(eps), len(min_samples), figsize=(5*len(eps), 5*len(min_samples)))\n",
    "  fig.tight_layout(pad=4.0)\n",
    "\n",
    "  for i in range(len(eps)):\n",
    "    for j in range(len(min_samples)):\n",
    "\n",
    "      dbscan = DBSCAN(eps=eps[i], min_samples=min_samples[j]).fit(X)\n",
    "\n",
    "      axs[i,j].set_title('eps=' + format(eps[i]) + ', min_samples='+ format(min_samples[j]))\n",
    "\n",
    "      axs[i,j].set_xlabel('X1')\n",
    "      axs[i,j].set_ylabel('X2')\n",
    "\n",
    "      axs[i,j].set_xlim(min[0], max[0])\n",
    "      axs[i,j].set_ylim(min[1], max[1])\n",
    "\n",
    "      data = np.concatenate((X, dbscan.labels_.reshape(-1, 1)), axis=1)\n",
    "      outlayers = data[data[:,2] == -1]\n",
    "      samples = data[data[:,2] != -1]\n",
    "\n",
    "      axs[i,j].scatter(samples[:,0], samples[:,1], c=samples[:,2], cmap='rainbow')\n",
    "      axs[i,j].scatter(outlayers[:,0], outlayers[:,1], c='black', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:21.244375Z",
     "start_time": "2021-11-02T10:03:17.381507Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_blobs(n_samples=500, cluster_std=[1.0, 2.0, 0.5], random_state=42)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.5, 1.0, 1.5], min_samples=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:23.292323Z",
     "start_time": "2021-11-02T10:03:21.255389Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.1, random_state=42)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.05, 0.15, 0.30], min_samples=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:25.104349Z",
     "start_time": "2021-11-02T10:03:23.305698Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_blobs(n_samples=500, cluster_std=2.0, random_state=42)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.5, 1.1, 2.0], min_samples=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:27.058348Z",
     "start_time": "2021-11-02T10:03:25.117907Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_blobs(n_samples=500, cluster_std=2.0, random_state=42)\n",
    "\n",
    "transformation = [[0.6, -0.6], [-0.4, 1.0]]\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.5, 1.2, 2.0], min_samples=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:29.036362Z",
     "start_time": "2021-11-02T10:03:27.060523Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X = np.random.rand(500, 2)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.01, 0.1, 0.5], min_samples=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:30.779454Z",
     "start_time": "2021-11-02T10:03:29.050791Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_circles(n_samples=500, factor=0.6, noise=.05)\n",
    "\n",
    "plot_dbscan(X=X, eps=[0.05, 0.15, 0.50], min_samples=[2, 5, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOEJN6ZDpIT6"
   },
   "source": [
    "## Caso práctico\n",
    "\n",
    "Ahora vamos a probar el algoritmo usando un dataset del repositorio [UCI](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset). Es un conjunto de datos de características sobre las sesiones online de compradores en una tienda virtual.\n",
    "\n",
    "Según la propia descripción del conjunto de datos:\n",
    "\n",
    "\n",
    "\n",
    "> The dataset consists of 10 numerical and 8 categorical attributes.\n",
    "The 'Revenue' attribute can be used as the class label.\n",
    ">\n",
    "> \"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another.\n",
    ">\n",
    "> The \"Bounce Rate\", \"Exit Rate\" and \"Page Value\" features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site. The value of \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session. The value of \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date.\n",
    ">\n",
    ">The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.\n",
    "\n",
    "Por tanto, tenemos 7 variables categóricas que habrá que transformar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:48.819801Z",
     "start_time": "2021-11-02T10:03:30.782147Z"
    },
    "id": "a6Z2u-8Uq4DB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00468/online_shoppers_intention.csv')\n",
    "target = raw['Revenue']\n",
    "raw.drop('Revenue', axis=1, inplace=True)\n",
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:48.877762Z",
     "start_time": "2021-11-02T10:03:48.827822Z"
    },
    "id": "8ldC0CGEq7ie"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "nominal_features = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "numeric_features = list(set(raw.columns) - set(nominal_features))\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(copy=False), numeric_features),\n",
    "        ('cat', OneHotEncoder(categories='auto'), nominal_features)])\n",
    "\n",
    "datos = preprocessor.fit_transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:03:48.893698Z",
     "start_time": "2021-11-02T10:03:48.884439Z"
    },
    "id": "yRIcj56bqSxf"
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENeJqsxGume9"
   },
   "source": [
    "Puesto que el hiper-parámetro $\\varepsilon$ se basa en la distancia, para ajustarlo, es interesante conocer la distancía máxima existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:04:01.149619Z",
     "start_time": "2021-11-02T10:03:48.895025Z"
    },
    "id": "s6BFumMDBx9R"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "distancias = kneighbors_graph(datos, 149, mode='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:04:02.655773Z",
     "start_time": "2021-11-02T10:04:01.151386Z"
    },
    "id": "9ra_Z1hGDgDS"
   },
   "outputs": [],
   "source": [
    "distancias.todense().flatten().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAwVMwZzuzjc"
   },
   "source": [
    "Ahora, podemos calcular medidas de calidad para DBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:04:02.664308Z",
     "start_time": "2021-11-02T10:04:02.659321Z"
    },
    "id": "Su2OkRvxsTaK"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "modelo_dbs = DBSCAN(eps=7.0, min_samples=75, metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:04:06.172318Z",
     "start_time": "2021-11-02T10:04:02.669814Z"
    },
    "id": "DpN917M6pWfc"
   },
   "outputs": [],
   "source": [
    "labs = modelo_dbs.fit_predict(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:04:28.592224Z",
     "start_time": "2021-11-02T10:04:06.182830Z"
    },
    "id": "LlJGGmrqFeCp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "print('Silhouette: ', silhouette_score(datos, labs))\n",
    "print('Rand Index (con ground truth): ', adjusted_rand_score(target, labs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mGouWToJhdD"
   },
   "source": [
    "Hay un proceso para determinar valores óptimos (locales) para los hyper-parámetros del algoritmo:\n",
    "\n",
    "1. Se calculan las distancias desde cada punto a los $minPoints-1$ más cercanos\n",
    "2. Se ordenan las distancias, se plotean y se elige el $\\varepsilon$ donde la curva es más pronunciada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:05:07.141043Z",
     "start_time": "2021-11-02T10:04:28.594251Z"
    },
    "id": "Au2SBO3zKtih"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=75)\n",
    "nbrs = neigh.fit(datos)\n",
    "distances, indices = nbrs.kneighbors(datos)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:05:46.545311Z",
     "start_time": "2021-11-02T10:05:07.143641Z"
    },
    "id": "xbbyqpluKyA3"
   },
   "outputs": [],
   "source": [
    "modelo_dbs = DBSCAN(eps=0.7, min_samples=75)\n",
    "labs = modelo_dbs.fit_predict(datos)\n",
    "print('Silhouette: ', silhouette_score(datos, labs))\n",
    "print('Rand Index (con ground truth): ', adjusted_rand_score(target, labs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DuxTtEUvAtD"
   },
   "source": [
    "---\n",
    "\n",
    "Creado por **Raúl Lara** (raul.lara@upm.es) y **Fernando Ortega** (fernando.ortega@upm.es)\n",
    "\n",
    "<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DBSCAN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
