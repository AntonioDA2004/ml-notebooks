{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LCqjgwwYfaY"
   },
   "source": [
    "# k-Means\n",
    "\n",
    "El algoritmo k-means es un algoritmo de aprendizaje no supervisado que se enmarca dentro de la familia de los algoritmos de *clustering*. Su objetivo, por tanto, consiste en agrupar datos no etiquetados. Veamos como funciona mediante un ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WAsJUrQ3AsD"
   },
   "source": [
    "Cargamos la librería `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:01:59.932082Z",
     "start_time": "2021-11-02T10:01:59.229157Z"
    },
    "id": "YSRykia3gia1"
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uG-Mc9to3Dts"
   },
   "source": [
    "Y prepramos un conjunto de datos sintético. Puesto que el objetivo de k-means es encontrar clusters, vamos a generar dos clusters con dos distribuciones gausianas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:00.971553Z",
     "start_time": "2021-11-02T10:01:59.934153Z"
    },
    "id": "-Q3mm43wgu_0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=300, n_features=2, centers=[[-3,-3], [3,3]], cluster_std=2.5, random_state=23)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.bwr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDVzuOqS92Di"
   },
   "source": [
    "No obstante, hay que tener en cuenta que el algoritmo, al ser no supervisado, no conocerá estas etiquetas por lo que trabajará únicamente con las coordenadas de los puntos para determinar los clusters. Las etiquetas (los colores rojo y azul) no se usarán. Deberá buscar los clusters \"a ciegas\", por lo que el conjunto de datos se verá visto del siguiente modo por el algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:01.180318Z",
     "start_time": "2021-11-02T10:02:00.975434Z"
    },
    "id": "9DrvL3nP-zM5"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI4ATJRd3hmP"
   },
   "source": [
    "El funcionamiento del algoritmo es muy sencillo:\n",
    "\n",
    "1.   Se define el número de clústeres (*k*) que se quieren construir.\n",
    "2.   Se inicializan *k* centroides con valores aleatorios dentro del rango de los datos. En algunas ocasiones, se eligen al azar *k* muestras del conjunto de datos para inicializar estos centroides.\n",
    "3.   Se asigna cada muestra del conjunto de datos al centroide más cercano.\n",
    "4.   Se actualizan los centroides con el valor promedio de todas las muestras que les han sido asignadas.\n",
    "5.   Se repiten los pasos 3 y 4 hasta que el algoritmo converja.\n",
    "\n",
    "Podemos ilustrar de forma gráfica este proceso haciendo uso de la implementación del algoritmo [`KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) de `skearn`. Las siguientes 4 imágenes muestran las 4 primeras iteraciones de una ejecución de k-means para 2 clusters ($k=2$). Como observamos se van desplazando los centroides hacia los centros de las nubes de puntos que generamos anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:02.576333Z",
     "start_time": "2021-11-02T10:02:01.182282Z"
    },
    "id": "XZylRMz_h6HW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# initial centroids\n",
    "centroids=np.array([[0,-0.1], [0,0.1]])\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20,4))\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "axs[0].set_title('k-means: iter 1')\n",
    "\n",
    "nearest = lambda p: 0 if np.linalg.norm(p-centroids[0])<np.linalg.norm(p-centroids[1]) else 1\n",
    "labels = nearest(X)\n",
    "\n",
    "labels = np.apply_along_axis(nearest, 1, X)\n",
    "\n",
    "axs[0].scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.bwr, alpha=0.25)\n",
    "axs[0].scatter(centroids[:,0], centroids[:,1], color=['b','r'], marker=\"x\", s=150)\n",
    "\n",
    "for i, iters in enumerate([1,2,3]):\n",
    "  kmeans = KMeans(n_clusters=2, init=centroids[:2], n_init=1, max_iter=iters, random_state=23)\n",
    "  kmeans.fit(X)\n",
    "  labels = kmeans.predict(X)\n",
    "\n",
    "  centroids = np.concatenate((centroids, kmeans.cluster_centers_))\n",
    "\n",
    "  axs[i+1].set_title('k-means: iter ' + str(iters+1))\n",
    "\n",
    "  axs[i+1].scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.bwr, alpha=0.25)\n",
    "  axs[i+1].scatter(centroids[:,0], centroids[:,1], color=['b','r']*(i+2), marker=\"x\", s=150)\n",
    "  axs[i+1].plot(centroids[::2,0], centroids[::2,1], color='blue', marker=\"x\", markersize=10)\n",
    "  axs[i+1].plot(centroids[1::2,0], centroids[1::2,1], color='red', marker=\"x\", markersize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIH7P4Sc78ws"
   },
   "source": [
    "Una vez concluido el entranamiento, se definirán dos regiones en todo el espacio de los datos, una para cada clúster. La siguiente imagen muestra estas regiones. La mayoría de datos se habrán agrupado correctamente, aunque, los que estén cerca de la frontera del clúster, tendrán más probabilidad de no agruparse en el clúster adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:02.920335Z",
     "start_time": "2021-11-02T10:02:02.589450Z"
    },
    "id": "zd9aTy219M2i"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init=centroids[:2], n_init=1, max_iter=3, random_state=23)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "h = .02 # step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.bwr,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvNc2pfRBJrU"
   },
   "source": [
    "Visto el funcionamiento del algoritmo podemos afirmar que la clave del mismo radica en la métrica utilizada para determinar la distancia entre dos muestras y, por tanto, asignar el centroide más cercano a cada muestra. Lo más habitual es emplear la distnacia euclidea:\n",
    "\n",
    "$$\n",
    "dist(x_i,x_j) = \\sqrt{(x_{i,1}-x_{j,1})^2 + (x_{i,2}-x_{j,2})^2 + \\dots + (x_{i,m}-x_{j,m})^2} = \\sqrt{\\sum_{f=1}^m (x_{i,f}-x_{j,f})^2}\n",
    "$$\n",
    "\n",
    "No obstante, pueden emplearse otras distancias en caso necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buUgPzzqwX__"
   },
   "source": [
    "## Caso práctico: k-Means sobre MNIST\n",
    "\n",
    "Vamos a desarrollar un ejemplo que nos permita entender cómo funciona el algoritmo de clústering KMeans con ayuda de dataset de MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p_HqL3hwtdC"
   },
   "source": [
    "Cargamos el dataset de MNIST, que ha sido denominado `digits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:03.042673Z",
     "start_time": "2021-11-02T10:02:02.928950Z"
    },
    "id": "cpj7tUw1wvZR"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvqeqjCSwt7O"
   },
   "source": [
    "Este dataset contiene un total de 1797 imágenes de dígitos manuscritos en imágenes de una resolución de 8x8 píxeles. Los dígitos van desde el 0 hasta el 9, por lo que, en total, hay 10 clases diferentes. El dataset está balanceado puesto que hay, aproximadamente, 180 muestras por cada clase.\n",
    "\n",
    "El dataset está preparado para que podamos visualizar la imágenes de los dígitos. En concreto, el campo `images` contiene una matriz cuadrada bidimensional de 8 filas y 8 columnas en las que cada valor se corresponde con la cantidad de color negro de un pixel.\n",
    "\n",
    "Veamos como se ha codificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:03.063611Z",
     "start_time": "2021-11-02T10:02:03.050168Z"
    },
    "id": "wu-MzOMqw5Ui"
   },
   "outputs": [],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5bPxIcHw6Am"
   },
   "source": [
    "En lugar de una representación matricial de los número podemos obtener, con ayuda de MatPlotLib una representación gráfica de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:03.081970Z",
     "start_time": "2021-11-02T10:02:03.073427Z"
    },
    "id": "9idbJm2KxEok"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:03.092327Z",
     "start_time": "2021-11-02T10:02:03.083916Z"
    },
    "id": "6KRGoILaxINs"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def paint_digits (images):\n",
    "  for index, image in enumerate(images):\n",
    "    plt.subplot(math.ceil(len(images)/5), 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:04.060039Z",
     "start_time": "2021-11-02T10:02:03.101135Z"
    },
    "id": "cxE24tu5xI5V"
   },
   "outputs": [],
   "source": [
    "paint_digits(mnist.images[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU-PhhUxxMGg"
   },
   "source": [
    "Evidentemente, esta representación matricial no es adecuada para ser utilizada por un algoritmo de *machine learning*. Necesitamos que cada imagen sea un vector unidimensional.\n",
    "\n",
    "Como siempre, los datos del dataset se encuentra en el objeto `data`. Observa las diferencias entre ambas codificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:04.067541Z",
     "start_time": "2021-11-02T10:02:04.062507Z"
    },
    "id": "lAZJNOcxxT-S"
   },
   "outputs": [],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:04.073926Z",
     "start_time": "2021-11-02T10:02:04.069487Z"
    },
    "id": "6nvyPKkKxVDM"
   },
   "outputs": [],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zzljTNcxY-B"
   },
   "source": [
    "Ahora que hemos codificado nuestras imágenes en vectores, vamos a proceder a ejecutar el algoritmo k-Means. Como sabemos, este algoritmo es de aprendizaje no supervisado, por lo que para esta actividad, ignoraremos completamente cualquier referencia a `mnist.target` que contiene las clases de cada uno de los digitos manuscritos.\n",
    "\n",
    "El objetivo de este ejemplo es entender cómo funciona el algoritmo k-Means y, por lo tanto, vamos a prescindir de cualquier medida de calidad. Esto implica que **NO** debemos dividir el dataset en entrenamiento y test. Utilizaremos **TODOS** los datos que tenemos para entrenar nuestro modelo k-Means y luego analizaremos los resultados obtenidos.\n",
    "\n",
    "Procedemos, por tanto, a ejecutar KMeans sobre los datos disponibles, es decir, sobre `mnist.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:09.800310Z",
     "start_time": "2021-11-02T10:02:04.075683Z"
    },
    "id": "2FRnnb3SxYPn"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 10, random_state=0)\n",
    "kmeans.fit(mnist.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txzoVe0TxuV4"
   },
   "source": [
    "Tras su entrenamiento, k-Means genera un centroide por cada cluster definido. Este centroide podemos entenderlo como la muestra promedio de cada uno de los clusters encontrados. La forma del centroide será idéntica a la forma de los datos con los que se ha entrenado.\n",
    "\n",
    "Podemos acceder a los centroides de k-Means mediante `kmeans.cluster_centers_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:09.833589Z",
     "start_time": "2021-11-02T10:02:09.804825Z"
    },
    "id": "vXzWH4eUxtjM"
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1Xqg_qTx3VQ"
   },
   "source": [
    "Puesto que los centroides son idénticos (en estructura) a cualquiera de los datos con los que hemos entrenado k-Means... ¡Podemos pintarlos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:10.228807Z",
     "start_time": "2021-11-02T10:02:09.836814Z"
    },
    "id": "o-2nlNXpx5pm"
   },
   "outputs": [],
   "source": [
    "paint_digits(list(map(lambda centroid: centroid.reshape(8, 8), kmeans.cluster_centers_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJT0oM48x78T"
   },
   "source": [
    "Recuerda, no se han utilizado las etiquetas en ningún momento. El algoritmo ha \"aprendido a escribir\" sin indicarle cuál era cada dígito.\n",
    "\n",
    "Vamos a analizar la solución. Como puedes ver, hay número que se parecen más (en forma) y números que se parecen menos. \n",
    "\n",
    "Compararemos la distancia (euclidea) entre los centroides para ver cuáles se parecen más. Para ello, podemos usar sklearn.metrics.pairwise.euclidean_distances. Esta función permite comparar los vectores fila de dos matrices (como los que tenemos en kmeans.cluster_centers_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvB9Ncp9yGLQ"
   },
   "source": [
    "Cargamos el módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:10.238758Z",
     "start_time": "2021-11-02T10:02:10.230872Z"
    },
    "id": "Jhe88r_hyIdK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj-e4sP8yI5h"
   },
   "source": [
    "Calculamos las distancias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:10.243518Z",
     "start_time": "2021-11-02T10:02:10.241051Z"
    },
    "id": "p_Aa2EwhyMcL"
   },
   "outputs": [],
   "source": [
    "dist = euclidean_distances(kmeans.cluster_centers_, kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZQs-SOAyOAb"
   },
   "source": [
    "Si mostramos `dist` directamente, será dificil analizar los resultados. Formateamos la salida de `numpy` para que la lectura sea más sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:10.254601Z",
     "start_time": "2021-11-02T10:02:10.245191Z"
    },
    "id": "GC8hm24eyQK6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1,floatmode='fixed')\n",
    "print(np.matrix(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOoRD-lpC4jX"
   },
   "source": [
    "## Inconvenientes de k-means\n",
    "\n",
    "En términos generales, el algoritmo k-means funciona bien. No obstante, tiene asociados una serie de problemas que hacen que, en determinadas circustancias, el algoritmo no funcione de forma correcta.\n",
    "\n",
    "Uno de sus grandes problemas es que k-means **es únicamente capaz de separar los datos linealmente**. Ilustremos esto haciendo funcionar k-means sobre los siguiente conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:10.587394Z",
     "start_time": "2021-11-02T10:02:10.256432Z"
    },
    "id": "FqggzlMqnbQV"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "circles, _ = datasets.make_circles(n_samples=500, factor=.5, noise=.05, random_state=23)\n",
    "axs[0].scatter(circles[:,0], circles[:,1])\n",
    "\n",
    "moons, _ = datasets.make_moons(n_samples=500, noise=.05, random_state=23)\n",
    "axs[1].scatter(moons[:,0], moons[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y27D4f4EourC"
   },
   "source": [
    "Como vemos, no es posible separar los clústers linealmente. Si ejecutamos k-means sobre dichos datasets para dos clusters (`k=2`) obtenemos el siguiente resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:11.035158Z",
     "start_time": "2021-11-02T10:02:10.594996Z"
    },
    "id": "xnWW0ZfGo57d"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, n_init=1, random_state=23)\n",
    "kmeans.fit(circles)\n",
    "\n",
    "labels = kmeans.predict(circles)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "axs[0].scatter(circles[:,0], circles[:,1], c=plt.cm.brg(labels/2, alpha=.25))\n",
    "axs[0].scatter(centroids[:,0], centroids[:,1], color=['b','r'], marker=\"x\", s=150)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, n_init=1, random_state=23)\n",
    "kmeans.fit(moons)\n",
    "\n",
    "labels = kmeans.predict(moons)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "axs[1].scatter(moons[:,0], moons[:,1], c=plt.cm.brg(labels/2, alpha=.25))\n",
    "axs[1].scatter(centroids[:,0], centroids[:,1], color=['b','r'], marker=\"x\", s=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySG7vwyz1PxS"
   },
   "source": [
    "Observamos que los centroides han obviado la forma de los clusters y se han centrado de tal forma que tengan igual número de puntos asociados a cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7nUKfcL1aFP"
   },
   "source": [
    "Otro problema de k-means es su **sensibilidad a los datos atípicos** o *outlayers*. Al actualizarse los centroides con la media de todos los puntos que se han asignado a los mismos, los valores atípicos tienen una influencia enorme sobre esta actualización, provocando, generalmente, que los centroides se desplacen más de lo esperado.\n",
    "\n",
    "Si tenemos el siguiente conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:11.296648Z",
     "start_time": "2021-11-02T10:02:11.040525Z"
    },
    "id": "XKrTZXNP100u"
   },
   "outputs": [],
   "source": [
    "blobs, _ = make_blobs(n_samples=300, n_features=2, centers=[[-3,-3], [3,3]], cluster_std=1.5, random_state=23)\n",
    "blobs = np.concatenate((blobs, np.array([[100,100]])))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(blobs[:,0], blobs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCF8dVjQ-gzM"
   },
   "source": [
    "Y ejecutamos k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T10:02:11.473787Z",
     "start_time": "2021-11-02T10:02:11.299677Z"
    },
    "id": "IqKpHGVc-iPI"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=1, random_state=23)\n",
    "kmeans.fit(blobs)\n",
    "\n",
    "labels = kmeans.predict(blobs)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(blobs[:,0], blobs[:,1], c=plt.cm.brg(labels/2, alpha=.25))\n",
    "plt.scatter(centroids[:,0], centroids[:,1], color=['b','r'], marker=\"x\", s=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK71AigN_eaw"
   },
   "source": [
    "Como vemos, se han definidos dos clústers: uno para el *outlayer* y otro para el resto de puntos. Esto supone un gran problema y requiere un filtrado previo de los *outlayers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BmehOdRotxa"
   },
   "source": [
    "Por último, el cálculo de las distancias entre cada punto y los centroides en cada iteración es **extremadamente lento** cuando se tiene un conjunto de datos grande. Para solventarlo, existe una variante llamada **Mini Batch k-Means**, disponible en `sklearn` en la clase [`MiniBatchKMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html).  Esta variante funciona de la siguiente manera: en lugar calcular el nuevo centroide considerando todas las muestras, lo hace con un subconjunto aleatorio de las mismas. De este modo, el tiempo de procesamiento se acelera y, al mismo tiempo, se reduce el *overfitting* y se amortigua el efecto de los *outlayers*. Sin embargo, introduce un nuevo hiperparámetro a optimizar: el número de puntos aleatorios que se seleccionan cada vez que se quiere modificar el centroide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYoqf8WXp5Vz"
   },
   "source": [
    "---\n",
    "\n",
    "Creado por **Fernando Ortega** (fernando.ortega@upm.es)\n",
    "\n",
    "<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "K-Means.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
