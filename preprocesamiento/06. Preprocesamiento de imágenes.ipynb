{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhA_1SGfGakt"
   },
   "source": [
    "# Preprocesamiento de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kM7ntIFGdAV"
   },
   "source": [
    "Definimos el **preprocesamiento de imágenes** como el conjunto de técnicas y/o operaciones que se aplican a las imágenes almacenadas en un ordenador para que éstas puedan ser utilizadas por los algoritmos de *machine learning*.\n",
    "\n",
    "En el ámbito de la informática, cualquier imagen, por compleja que sea, está siempre compuesta por pixeles. Los píxeles se agrupan formando una matriz bidimensional que define el tamaño de la imagen. Cuantas más filas y columnas tengan esa matriz, más resolución tendrá la imagen. A continuación, se muestra una imagen de 55x55 píxeles:\n",
    "\n",
    "![Imagen pixelada](https://i.ibb.co/YfPgNPz/pixel-image.jpg)\n",
    "\n",
    "Cuando se trabaja con imágenes, generalmente, se distinguen dos tipos de imágenes: las imágenes en blanco y negro (o escala de grises) y las imágenes a color. Las primeras definen el color de cada uno de sus pixeles mediante un número de 0 a 255 que indica la cantidad de blanco que posee dicho píxel: el valor 0 se corresponden con la ausencia de blanco (negro) y el valor 255 se corresponde con el blanco total. Los valores intermedios permiten definir los diferentes tonos de gris existentes. Esta sería la imagen anterior en escala de grises:\n",
    "\n",
    "![Imagen pixelada en escala de grises](https://i.ibb.co/sVHPrV8/pixel-image-escala-de-grises.jpg)\n",
    "\n",
    "Por su parte, las segundas consiguen generar el color mediante la adición de tres componentes lumínicos: el componente rojo, el componente azul y el componente verde. Es por esto por lo que a estas imágenes se las conoce como RGB (del inglés, *Red-Green-Blue*). Mediante la combinación de estos tres componentes puede conseguirse representar cualquier color. Por tanto, cuando definamos una imagen en color, cada píxel vendrá definido por tres valores: la cantidad de rojo, la cantidad de verde y la cantidad de azul de píxel. Todos ellos, al igual que las imágenes en escala de grises, vendrán definidos con un valor numérico de 0 a 255, siendo 0 la ausencia del componente y 255 la totalidad del componente. Las siguientes imágenes muestran la imagen original separando cada uno de sus canales de RGB:\n",
    "\n",
    "![Imagen pixelada separa por componentes RGB](https://i.ibb.co/6RzDZK4/pixel-image-rgb-decomposition.jpg)\n",
    "\n",
    "Dada esta representación computacional de las imágenes, la idea general del preprocesamiento de datos es sencilla: transformar una colección de píxeles en un *array* unidimensional que contenga toda la información contenida en la imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba8alPsfIwMD"
   },
   "source": [
    "## Trasformación básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI7BEA8YIytb"
   },
   "source": [
    "En este apartado vamos a estudiar el concepto fundamental en el que radica la trasformación de imágenes. \n",
    "\n",
    "Como es lógico, el tipo de imágen más sencillo con el que podemos trabajar es una imágen en escala de grises. Supongamos, por tanto, que tenemos la siguiente imagen de 4x4 píxeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ewjiq90eLjAZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.array([[0,0,0,0],[0,255,255,0],[0,255,255,0],[0,0,0,0]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1582886017853,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "0oGHmctxL2BK",
    "outputId": "7c3a3b85-eaa0-445a-9a54-50f5892ea509"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhN1JsFaNsuK"
   },
   "source": [
    "Como podemos observar, la imagen se ha definido en un *array* de dos dimensiones compuesto por 4 filas y 4 columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1743,
     "status": "ok",
     "timestamp": 1582886017854,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "qiBtcbn2N8T-",
    "outputId": "8521c100-74c0-4590-82f5-e5e0f7353238"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zEhRODtN-dD"
   },
   "source": [
    "Esta representación de las imágenes no es válida para ser utilizada por los algoritmos de *machine learning*, ya que éstos requieren que sus datos de entrada estén almacenados en *arrays* unidimensionales.\n",
    "\n",
    "Por tanto, lo que debemos hacer es transformar el *array* bidimensional en un array unidimensional de tal manera que, una imagen representada en una matriz de *N* filas y *M* columnas pase a ser un *array* de dimensión *NxM*.\n",
    "\n",
    "Para ello hacemos uso del método `ravel()` de la clase `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 1736,
     "status": "ok",
     "timestamp": 1582886017855,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "ImzsdbCZhz1S",
    "outputId": "fb362bc4-4c2f-450b-e009-a0868675beba"
   },
   "outputs": [],
   "source": [
    "img.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLXEbNH9iOw1"
   },
   "source": [
    "Podemos observar que las primeras cuatro posiciones se corresponden con la primera fila, las segundas cuatro posiciones se corresponden con la segunda fila y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh3TldxOiXto"
   },
   "source": [
    "Este es el formato más habitual en el que encontraremos las imágenes en los diferentes conjuntos de datos que utilicemos. El problema que tenemos es que, si queremos analizar visualmente estas imágenes, no podemos, por lo que tenemos que volver a transformarlas a una estructura bidimensional mediante `reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 2536,
     "status": "ok",
     "timestamp": 1582886018663,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "6_O2T5f6iqKu",
    "outputId": "5cf593e3-6afd-435b-ae64-99cda0bc54da"
   },
   "outputs": [],
   "source": [
    "img_1d = img.ravel()\n",
    "io.imshow(img_1d.reshape([4,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4U-j4b3jLe6"
   },
   "source": [
    "## Imágenes a color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEEvp7YKjRKg"
   },
   "source": [
    "Generalmente, trabajar con imágenes en blanco y negro es suficiente para obtener una información representativa sobre el contenido de la imagen. Trabajar con imágenes en blanco y negro en lugar de imágenes a color tiene un gran ventaja: ocupan menos espacio.\n",
    "\n",
    "Que las imágenes ocupen menos espacio significa que:\n",
    "\n",
    "- Su consumo de memoria es más pequeño\n",
    "- La dimensionalidad del conjunto de datos es más reducida\n",
    "\n",
    "Ambas son condiciones deseables en todo algoritmo de *machine learning*.\n",
    "\n",
    "Sin embargo, existen situaciones en las que el color es importante. Supongamos que disponemos de la siguiente imagen de una señal de tráfico que limita la velocidad a 40 km/h:\n",
    "\n",
    "![Límte 40km/h](https://i.ibb.co/rF9zGrD/limite-40-color.png)\n",
    "\n",
    "Ahora, disponemos de la misma imagen, pero para limitar la velocidad en un tramo de obras:\n",
    "\n",
    "![Límte 40km/h obras](https://i.ibb.co/D10Qs5N/limite-40-obras.png)\n",
    "\n",
    "¿Qué sucede si ponemos ambas imágenes en blanco y negro?\n",
    "\n",
    "![Límte 40km/h blanco y negro](https://i.ibb.co/P9gT297/limite-40-bn.png)\n",
    "\n",
    "Cuesta distinguir, a simple vista, ambas señales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3ThmYvwlTkG"
   },
   "source": [
    "La definición de imágenes en color se logra mediante *arrays* de 3 dimensiones en los que las dos primera posiciones representan el píxel al que se hace referencia y la tercera reasenta el canal de color en el que se está marcando la intensidad de dicho píxel.\n",
    "\n",
    "**Ejercicio:** genera manualmente una imagen a color, muéstrala con `io.imshow()` y transformalá en un vector unidimensional.\n",
    "\n",
    "Existen otras muchas formas de representar el color y podemos convertirlas fácilmente con la librería `scikit-image`. Algunos de los métodos incluidos son:\n",
    "\n",
    "- [Conversión entre modelos de color](https://scikit-image.org/docs/stable/user_guide/transforming_image_data.html#conversion-between-color-models)\n",
    "- [RGBA a RGB](https://scikit-image.org/docs/stable/user_guide/transforming_image_data.html#conversion-from-rgba-to-rgb-removing-alpha-channel-through-alpha-blending)\n",
    "- [Color y escala de grises](https://scikit-image.org/docs/stable/user_guide/transforming_image_data.html#conversion-between-color-and-gray-values)\n",
    "- [Inversión de colores](https://scikit-image.org/docs/stable/user_guide/transforming_image_data.html#image-inversion)\n",
    "\n",
    "En general, tenemos muchos métodos de trasformación de colores en [`skimage-colors`](https://scikit-image.org/docs/stable/api/skimage.color.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0tydjXAmKrD"
   },
   "source": [
    "## Máscaras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ea-tHX0mP18"
   },
   "source": [
    "¿Son todos los píxeles de una imagen igual de importantes? Parece lógico pensar que no. Cuando se toma una fotografía la zona de interés suele estar en el centro de la misma, siendo las esquinas desde el punto de visto de la información de la fotografía.\n",
    "\n",
    "Algunos ejemplos tomados de *lorem picsum*:\n",
    "\n",
    "![Ejemplo 1](https://picsum.photos/id/1011/200)\n",
    "![Ejemplo 2](https://picsum.photos/id/237/200)\n",
    "![Ejemplo 3](https://picsum.photos/id/106/200)\n",
    "\n",
    "Añadir píxeles innecesarios a una imagen dificulta enormemente el aprendizaje a los algoritmos de *machine learning*. Una de las técnicas más utilizadas para eliminar esta información consiste en aplicar máscaras sobre las imágenes de tal manera que todos los píxeles que queden fuera de la máscara se fijen a un color predefinido (generalmente negro) y sean \"ignorados\" por los algoritmos de *machine learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6D61Gmpqhhd"
   },
   "source": [
    "Veamos algunos ejemplos usando la siguiente fotografía como referencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 2527,
     "status": "ok",
     "timestamp": 1582886018664,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "n8sZ_-YfqntG",
    "outputId": "a71fa315-ece4-4510-d18f-f721e167ef04"
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "camera = data.camera()\n",
    "io.imshow(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0sX3GoPqzcf"
   },
   "source": [
    "Ponemos a negro las 20 primeras filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 3026,
     "status": "ok",
     "timestamp": 1582886019175,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "RUCXZE9fq2mM",
    "outputId": "7e624755-3eba-401d-9808-a89c7af7e367"
   },
   "outputs": [],
   "source": [
    "camera = data.camera()\n",
    "camera[:20] = 0\n",
    "io.imshow(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLaQSQO8rgh3"
   },
   "source": [
    "Ponemos a blanco todos los píxles que tengan una intensidad inferior a 87:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 3637,
     "status": "ok",
     "timestamp": 1582886019794,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "wR9lfM7dri-z",
    "outputId": "9ccd5f22-b674-4af2-8192-3b9aabb8bc7c"
   },
   "outputs": [],
   "source": [
    "camera = data.camera()\n",
    "mask = camera < 87\n",
    "camera[mask] = 255\n",
    "io.imshow(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoGYDavir0p6"
   },
   "source": [
    "Ponemos en negro todos los píxeles que no pertenezcan a la circunferencia interior de la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 3628,
     "status": "ok",
     "timestamp": 1582886019794,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "Syx33Ecar01s",
    "outputId": "66ce26a1-0009-41fb-a57a-0b61f95f70b1"
   },
   "outputs": [],
   "source": [
    "camera = data.camera()\n",
    "nrows, ncols = camera.shape\n",
    "row, col = np.ogrid[:nrows, :ncols]\n",
    "cnt_row, cnt_col = nrows / 2, ncols / 2\n",
    "outer_disk_mask = ((row - cnt_row)**2 + (col - cnt_col)**2 > (nrows / 2)**2)\n",
    "camera[outer_disk_mask] = 0\n",
    "io.imshow(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGisXbdMuHK7"
   },
   "source": [
    "**Ejercicio:** crea una máscara que elimine 25 píxles del exterior de una imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDvactivubE4"
   },
   "source": [
    "## scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgNuYISmudJu"
   },
   "source": [
    "`scikit-image` es una de las librerías de referencia para trabajar con imágenes en python. \n",
    "\n",
    "Como hemos visto, `scikit-image` opera con imágenes codificadas en *arrays* de `numpy`. Se permiten los siguientes tipos de datos:\n",
    "\n",
    "| Tipo de datos        \t| Rango             \t|\n",
    "|---------------------\t|-------------------\t|\n",
    "| uint8               \t| 0 to 255          \t|\n",
    "| uint16                | 0 to 65535         \t|\n",
    "| uint32 \t              | 0 to 2^32 - 1      \t|\n",
    "| float               \t| -1 to 1 or 0 to 1 \t|\n",
    "| int8                \t| -128 to 127       \t|\n",
    "| int16               \t| -32768 to 32767   \t|\n",
    "| int32               \t| -2^31 to 2^31 - 1 \t|\n",
    "\n",
    "Además, admite conversiones entre tipos utilizando los métodos del submódulo [`skimage.util`](https://scikit-image.org/docs/stable/api/skimage.util.html):\n",
    "\n",
    "* `img_as_float`\n",
    "* `img_as_ubyte`\n",
    "* `img_as_uint`\n",
    "* `img_as_int`\n",
    "\n",
    "Por otro lado, `scikit-image` incorpora diversas imágenes de ejemplo con las que podemos \"jugar\" en el módulo [`skimage.data`](https://scikit-image.org/docs/stable/api/skimage.data.html).\n",
    "\n",
    "**Ejercicio:** prueba a convertir la imagen del cohete (*rocket*) a distintos tipos y el contenido de los arrays y la visualización de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlAtu7EA0Szr"
   },
   "source": [
    "## Ajuste de contraste y exposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jAw-pC_1L1X"
   },
   "source": [
    "Durante el procesamiento de imágenes es probable que nos encontremos con fotografías que ha sido tomadas en condiciones lumínicas no ideales o con una configuración inadecuada de la lente. Esto suele traducirse en imágenes en las que resulta complicado extraer información. Mediante el ajuste del contraste y la exposición de una imagen podemos enfatizar los elementos más significativos de la misma para que le sea más sencillo al algoritmo de *machine learning* extraer información sobre ella.\n",
    "\n",
    "El módulo [`skimage.exposure`](https://scikit-image.org/docs/stable/api/skimage.exposure.html) contiene mucho métodos para preprocesar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLeJwgq34duL"
   },
   "outputs": [],
   "source": [
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LXJS6ZH4ode"
   },
   "source": [
    "Vamos a comparar diferentes transformaciones sobre la siguiente imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 4546,
     "status": "ok",
     "timestamp": 1582886020771,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "h9u5Fdru4sMe",
    "outputId": "b3a64922-64e2-4909-9ed1-6b0cf80d707d"
   },
   "outputs": [],
   "source": [
    "moon = data.moon()\n",
    "io.imshow(moon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDFGdref2jL3"
   },
   "source": [
    "Una de las técnicas más populares es la [corrección del gamma](https://en.wikipedia.org/wiki/Gamma_correction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 4534,
     "status": "ok",
     "timestamp": 1582886020772,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "r7_lH3Kw4AjA",
    "outputId": "7d2d8067-8a29-4059-abf8-23c85d54b873"
   },
   "outputs": [],
   "source": [
    "moon = data.moon()\n",
    "gamma = 5.9 #@param {type: \"slider\", min:0, max:10, step:0.1}\n",
    "gain = 5.1 #@param {type: \"slider\", min:0, max:10, step:0.1}\n",
    "io.imshow(exposure.adjust_gamma(moon, gamma, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-Mpgxr95CW6"
   },
   "source": [
    "En definitiva, casi todas las transformaciones que hagamos, se basan en el histograma de la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 4468,
     "status": "ok",
     "timestamp": 1582886020773,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "NJAaRUsv5Lnn",
    "outputId": "bef359b8-4d83-443b-d18d-5df3dee87cbc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(moon.ravel(), bins=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "executionInfo": {
     "elapsed": 4441,
     "status": "ok",
     "timestamp": 1582886020773,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "9hvNsRoF7zc7",
    "outputId": "64dea17e-e19b-422a-f81d-ac6a3a1b3dbc"
   },
   "outputs": [],
   "source": [
    "exposure.histogram(moon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pzaIVun74lw"
   },
   "source": [
    "Una de las formas de ajustar el contraste es reescalar los píxeles al mínimo y máximo permitido (0 y 255 generalmente). Esto podemos hacerlo usando `rescale_intensity()`. Sin embargo, en el ejemplo de la luna, no tiene sentido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4424,
     "status": "ok",
     "timestamp": 1582886020774,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "vUGn4WT28ynk",
    "outputId": "132a7078-bd3c-4574-aaa8-72dce7e56957"
   },
   "outputs": [],
   "source": [
    "moon.min(), moon.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T8eB4xY86xw"
   },
   "source": [
    "No obstante, el método es parametrizable y podemos ajustar la imagen al rango que queramos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 4841,
     "status": "ok",
     "timestamp": 1582886021198,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "GkNHX0Ty9Bpv",
    "outputId": "044d1195-4600-4213-dc2a-d672f46428ea"
   },
   "outputs": [],
   "source": [
    "min = 10  #@param {type: \"slider\", min: 0, max: 255}\n",
    "max = 114  #@param {type: \"slider\", min: 0, max: 255}\n",
    "io.imshow(exposure.rescale_intensity(moon, in_range=(min, max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 5069,
     "status": "ok",
     "timestamp": 1582886021439,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "mAMvTEoF9nfL",
    "outputId": "70cb4741-3edf-4a06-c400-efb4a06c26ef"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(exposure.rescale_intensity(moon, in_range=(min, max)).ravel(), bins=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JCj4jOC92Oa"
   },
   "source": [
    "Es habitual que los valores de reescalado se identifiquen mediante los percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5053,
     "status": "ok",
     "timestamp": 1582886021440,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "I8J4WVsA99tN",
    "outputId": "9d911e88-251c-47dd-d946-9301badf4ec4"
   },
   "outputs": [],
   "source": [
    "p_min, p_max = np.percentile(moon, (20, 80))\n",
    "p_min, p_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 5526,
     "status": "ok",
     "timestamp": 1582886021923,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "tJpmVXMJ-zIY",
    "outputId": "0ecf492d-64ef-47e2-80dd-229aa7c819e6"
   },
   "outputs": [],
   "source": [
    "io.imshow(exposure.rescale_intensity(moon, in_range=(p_min, p_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8CPoMloV_XH"
   },
   "source": [
    "También es frecuente igualar los histogramas a una fotografía que actua como referente mediante la función [`match_histograms`](https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.match_histograms). De este modo, podemos centrarnos en ajustar correctamente el histograma de una única fotografía y luego hacer que todas las fotografías se ajusten a la misma. Visualmente, si trabajamos con imágenes a color, conseguirmos que todas las dos imágenes tengan tonalidades de color similares como se muestra en este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 6623,
     "status": "ok",
     "timestamp": 1582886023043,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "bXhjL9tgWVI3",
    "outputId": "fc2a0368-8e92-41f7-de61-ae76c17e2100"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage import exposure\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "reference = data.coffee()\n",
    "image = data.chelsea()\n",
    "\n",
    "matched = match_histograms(image, reference, multichannel=True)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "for aa in (ax1, ax2, ax3):\n",
    "    aa.set_axis_off()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original')\n",
    "ax2.imshow(reference)\n",
    "ax2.set_title('Referencia')\n",
    "ax3.imshow(matched)\n",
    "ax3.set_title('Ajustada')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nccxhsxr_Ifr"
   },
   "source": [
    "**Ejercicio:** analiza el resto de métodos del módulo `skimage.exposure` ([https://scikit-image.org/docs/stable/api/skimage.exposure.html#module-skimage.exposure](https://scikit-image.org/docs/stable/api/skimage.exposure.html#module-skimage.exposure)). ¿Qué hacen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmFIDYE1v_Mi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gapmxnBemFmv"
   },
   "source": [
    "## Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEoIhl_stg_2"
   },
   "source": [
    "El principal objetivo de los algoritmos de *machine learning* en encontrar pautas o patrones en los datos de entrada con el objetivo de darles un **valor añadido**. Para ello, es fundamental que alimentemos al algoritmo con los datos \"en crudo\". Dicho de otro modo, tenemos que evitar sesgar los datos de entrada porque, en ese caso, estaremos condicionando la salida del algoritmo.\n",
    "\n",
    "No obstante, dejar los datos en \"en crudo\" tiene un problema asociado: el espacio de búsqueda de las soluciones es mayor y, por ende, es más difícil que nuestro algoritmo aprenda. Es por ello por lo que, en algunas ocasiones, conviene aplicar algunas trasformaciones a los datos de entrada que orienten a nuestro algoritmo de *machine learning* hacia la solución al problema que queremos resolver.\n",
    "\n",
    "Cuando trabajamos con imágenes, podemos aplicar filtros a las mismas para facilitar la identificación de la información que contienen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiZAyGHS2Zbg"
   },
   "source": [
    "Vamos a ver algunos de los filtros contenidos en [`skimage.filters`](https://scikit-image.org/docs/stable/api/skimage.filters.html) usando como ejemplo la imagen del astronauta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 6611,
     "status": "ok",
     "timestamp": 1582886023044,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "L8c4wGtMmKVf",
    "outputId": "c25018bc-5be8-48b1-f366-e2c557f37db2"
   },
   "outputs": [],
   "source": [
    "astronaut = data.astronaut()\n",
    "io.imshow(astronaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiEEVHaD2jjr"
   },
   "source": [
    "La mayoría de filtros estan preparados para trabajar en escala de grises, por lo que convertimos nuestra imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 7128,
     "status": "ok",
     "timestamp": 1582886023576,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "fsFrEwFNnh1X",
    "outputId": "3bc3ee31-c9e7-413b-b408-6a4b8bdad354"
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "astronaut = rgb2gray(astronaut)\n",
    "io.imshow(astronaut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsSJYdOO2r89"
   },
   "source": [
    "Cargamos el módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of-Lts0Hm5J0"
   },
   "outputs": [],
   "source": [
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nMw-sDL2uX2"
   },
   "source": [
    "El filtro [`gaussian`](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian) permite desenfocar las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 7597,
     "status": "ok",
     "timestamp": 1582886024065,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "kqPA4UsjoV2s",
    "outputId": "3a79cdca-0652-45e5-faf8-a39f718f76b8"
   },
   "outputs": [],
   "source": [
    "sigma = 0.5  #@param {type: \"slider\", min: 0, max: 10, step:0.5}\n",
    "io.imshow(filters.gaussian(astronaut, sigma=sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58J80H2e3P4o"
   },
   "source": [
    "El filtro [`unsharp_mask`](https://scikit-image.org/docs/stable/api/skimage.filters.html#unsharp-mask) permite resaltar los bordes de la imagen y desenfocar las zonas sin bordes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 8346,
     "status": "ok",
     "timestamp": 1582886024821,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "1bQNfIRcsa_T",
    "outputId": "c88409c2-8fbf-4fbc-a482-01d835fd85f3"
   },
   "outputs": [],
   "source": [
    "radius = 98.5  #@param {type:\"slider\", min:0.5, max:100, step:0.5}\n",
    "io.imshow(filters.unsharp_mask(astronaut, radius=radius))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeQT7iVc35WX"
   },
   "source": [
    "El filtro [`median`](https://scikit-image.org/docs/stable/api/skimage.filters.html#median) \"aplana\" una imagen calculando el valor medio local de cada pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 8819,
     "status": "ok",
     "timestamp": 1582886025304,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "cxT1MTYZpep5",
    "outputId": "a14fb1a5-571b-428c-a451-a31c819e1e63"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.median(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfIKg8K44ojd"
   },
   "source": [
    "Otra tendencia habitual es binarizar los datos de tal forma que cada píxel tome el valor blanco o negro. Para ello, se establece un umbral (*threshold*) a patir del cual el píxel se asume como fondo o no. Existen diferentes algoritmos para determinar el umbral y podemos ver sus diferencias con [`try_all_threshold`](https://scikit-image.org/docs/stable/api/skimage.filters.html#try-all-threshold):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "executionInfo": {
     "elapsed": 10485,
     "status": "ok",
     "timestamp": 1582886026988,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "IZbNXd3KrV0s",
    "outputId": "8b27cb37-284c-46e7-9f10-c79d8a7d01e0"
   },
   "outputs": [],
   "source": [
    "fig, ax = filters.try_all_threshold(astronaut, figsize=(10, 10), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQLFtWn75L2l"
   },
   "source": [
    "Tambien eshabitual centrarse en los bordes de las imágenes, ya que estos, a menudo, contienen la mayor parte de la información de las mismas. Existen infinidad de algoritmos para identificar los bordes. A continuación, algunos ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zgmaqRR5WL-"
   },
   "source": [
    "- [`sobel`](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.sobel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 10474,
     "status": "ok",
     "timestamp": 1582886026989,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "irFLcXw0ppUo",
    "outputId": "97c944cc-fd4d-4b84-d1e1-0c01f8aa5618"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.sobel(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWQ8htjp5jHW"
   },
   "source": [
    "- [`scharr`](https://scikit-image.org/docs/stable/api/skimage.filters.html#scharr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 10453,
     "status": "ok",
     "timestamp": 1582886026989,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "Hs8BO_8hqbcn",
    "outputId": "bc3df020-1e75-4986-9809-bbe07d13a766"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.scharr(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI2Mvagn5iXa"
   },
   "source": [
    "- [`prewitt`](https://scikit-image.org/docs/stable/api/skimage.filters.html#prewitt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 11030,
     "status": "ok",
     "timestamp": 1582886027577,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "vmVGhM2Rqo98",
    "outputId": "6e9f8b8e-74f9-4937-ede3-bf78f8912fe9"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.prewitt(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqhbHNNc506Q"
   },
   "source": [
    "- [`roberts`](https://scikit-image.org/docs/stable/api/skimage.filters.html#roberts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 11018,
     "status": "ok",
     "timestamp": 1582886027578,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "Vc1xoHI_qvO4",
    "outputId": "87aac28b-309b-417f-a3d5-3f31e75d79af"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.roberts(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qefl7Wt584v"
   },
   "source": [
    "- [`laplace`](https://scikit-image.org/docs/stable/api/skimage.filters.html#laplace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 11709,
     "status": "ok",
     "timestamp": 1582886028292,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "_CCziTivq1n1",
    "outputId": "f8f9cc28-8d10-4bd0-e412-b9e61be8b487"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.laplace(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Fc0WvZG6dBZ"
   },
   "source": [
    "- [`frangi`](https://scikit-image.org/docs/stable/api/skimage.filters.html#frangi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 12055,
     "status": "ok",
     "timestamp": 1582886028654,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "LALybtREsA-4",
    "outputId": "731ac3d3-79ad-4cbe-839c-b0725c646fdf"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.frangi(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4FVIqzz6feG"
   },
   "source": [
    "- [`hessian`](https://scikit-image.org/docs/stable/api/skimage.filters.html#hessian):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 12388,
     "status": "ok",
     "timestamp": 1582886029008,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "bhsNd3h3sIfz",
    "outputId": "f75c23bb-e2e9-479f-d65a-c8d8116ac5d6"
   },
   "outputs": [],
   "source": [
    "io.imshow(filters.hessian(astronaut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZszMJgC6iC1"
   },
   "source": [
    "**Ejercicio:** observa que la mayoría de filtros incorporan una máscara. ¿Puedes aplicarla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYJbvSRRv8tO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xla3vBY47U10"
   },
   "source": [
    "# Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XGOkzHeEcBE"
   },
   "source": [
    "El módulo [`skimage.transform`](https://scikit-image.org/docs/stable/api/skimage.transform.html) contiene diferentes algoritmos de trasformación de imágenes. El objetivo de las trasformaciones es muy similar al de los filtros: generar una nueva imágen en la que sea más sencillo recuperar la información. La diferencia entre filtro y transformación es, por tanto, semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrMmdCknE6j1"
   },
   "outputs": [],
   "source": [
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xCjzeFcE7Jr"
   },
   "source": [
    "[`rotate`](https://scikit-image.org/docs/stable/api/skimage.transform.html#rotate) nos permite girar las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 12848,
     "status": "ok",
     "timestamp": 1582886029490,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "lBtlkFj_DZRz",
    "outputId": "11d7befa-923c-42ef-9260-2c501ba78451"
   },
   "outputs": [],
   "source": [
    "angle = 0  #@param {type:\"slider\", min:0, max:359}\n",
    "io.imshow(transform.rotate(astronaut,angle=angle))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-hTaHgFXa8"
   },
   "source": [
    "[`resize`](https://scikit-image.org/docs/stable/api/skimage.transform.html#resize) nos permite redimensionar una imagen pudiendo cambiar el ratio de alto y ancho:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 13274,
     "status": "ok",
     "timestamp": 1582886029927,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "vFsDF4LtCtQI",
    "outputId": "3144699c-dcf4-4163-98cb-b404ca3f4ae6"
   },
   "outputs": [],
   "source": [
    "h = 200  #@param {type:\"slider\", min:1, max:500}\n",
    "w = 200  #@param {type:\"slider\", min:1, max:500}\n",
    "io.imshow(transform.resize(astronaut,output_shape=(h,w)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQKsm8XjFzyp"
   },
   "source": [
    "[`rescale`](https://scikit-image.org/docs/stable/api/skimage.transform.html#rescale) nos permite re-escalar una imagen conservando el ratio de alto y ancho. Por lo general, este método se usa para reducir el tamaño de una imagen, lo cual ayuda a eliminar información superflua de la misma, y facilita la obtenición de la información esencial que contiene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1582886048796,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "WlIUTu3eDlRx",
    "outputId": "6e80f35e-e583-4763-9557-059f2b9eb7b6"
   },
   "outputs": [],
   "source": [
    "scale = 0.3  #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
    "io.imshow(transform.rescale(astronaut,scale=scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs-ptohjGmtH"
   },
   "source": [
    "El reescalado de imágenes no es único y existen otros métodos como [`pyramid_reduce`](https://scikit-image.org/docs/stable/api/skimage.transform.html#pyramid_reduce) que prometen una reducción más certera de la imagen original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 14077,
     "status": "ok",
     "timestamp": 1582886030744,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "nVjuHW8yAeM3",
    "outputId": "d5f6f983-9020-4189-a29b-a45c6c41d608"
   },
   "outputs": [],
   "source": [
    "downscale = 28  #@param {type:\"slider\", min:1, max:100}\n",
    "io.imshow(transform.pyramid_reduce(astronaut,downscale=downscale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIrGIw8BHOhw"
   },
   "source": [
    "Incluso permiten reconstruir la imagen (o al menos lo intentan):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 14522,
     "status": "ok",
     "timestamp": 1582886031196,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "JAaea4r0EJ6K",
    "outputId": "fd7a7a61-723e-4e5b-c493-beb9167d14f6"
   },
   "outputs": [],
   "source": [
    "scale = 3  #@param {type:\"slider\", min:1, max:100}\n",
    "reduced = transform.pyramid_reduce(astronaut,downscale=scale)\n",
    "io.imshow(transform.pyramid_expand(reduced,upscale=scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igsxl7pWHyGZ"
   },
   "source": [
    "Otro tipo de transformaciones que podemos aplicar a la imagen es una proyección de la misma. Una de ellas es las transformación *radon* de la que puedes encontrar más información [aquí](https://scikit-image.org/docs/stable/auto_examples/transform/plot_radon_transform.html#sphx-glr-auto-examples-transform-plot-radon-transform-py).\n",
    "\n",
    "Visualmente, no obtenemos mucha información de esta transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 16528,
     "status": "ok",
     "timestamp": 1582886033207,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "FUbjxmDd7VHD",
    "outputId": "80a15e69-b81a-435b-8fb4-f64da4ddd504"
   },
   "outputs": [],
   "source": [
    "radon = transform.radon(astronaut)\n",
    "io.imshow(radon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDCcy2sNIN7m"
   },
   "source": [
    "Pero si desacemos la transformación vemos que se recupera buena parte de la información de la fotografía original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 17969,
     "status": "ok",
     "timestamp": 1582886034656,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "z5o45T6gChQL",
    "outputId": "8d3eaddb-fa67-4271-c54c-5dfbdd16d250"
   },
   "outputs": [],
   "source": [
    "io.imshow(transform.iradon(radon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 23581,
     "status": "ok",
     "timestamp": 1582886040273,
     "user": {
      "displayName": "Fernando Ortega Requena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDKoun1eFTfAu1UKuTzMsouodof0cWSRBHrA62HzQ=s64",
      "userId": "02003917424124170753"
     },
     "user_tz": -60
    },
    "id": "8tc5pPSvCjDE",
    "outputId": "d69fd08d-04a8-4b4e-da80-969595e91db7"
   },
   "outputs": [],
   "source": [
    "io.imshow(transform.iradon_sart(radon))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdSP9J0VIZiw"
   },
   "source": [
    "Lo que quiere decir que decir que la transformación contiene una representación de bajo nivel del contenido (información) de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_e8W_l-IqsX"
   },
   "source": [
    "## scikit-image.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMufPxbtIwGm"
   },
   "source": [
    "El módulo [`skimage.io`](https://scikit-image.org/docs/stable/api/skimage.io.html), que hemos estado utilizando para pintar las imágenes, contiene diversas herramientas para leer y escribir imágenes en disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgZ2_ZhzOKQF"
   },
   "source": [
    "# Ejercicio final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocmoM9QtOMAj"
   },
   "source": [
    "Preprocesa las imágenes diponibles en el siguiente conjunto de datos: [flower-color-images](https://www.kaggle.com/olgabelitskaya/flower-color-images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tWnMy0xv6hQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPyRSdrr9A08"
   },
   "source": [
    "<hr>\n",
    "\n",
    "Creado por **Fernando Ortega** (fernando.ortega@upm.es)\n",
    "\n",
    "<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "06. Preprocesamiento de imágenes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
