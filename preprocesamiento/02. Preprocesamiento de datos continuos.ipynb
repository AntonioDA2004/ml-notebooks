{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. Preprocesamiento de datos continuos.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mclP9DsAal9s"},"source":["# Pre-procesamiento de datos continuos\n","\n","Entendemos por datos continuos a aquellos datos numéricos que pueden tomar cualquier valor (real) en un rango preestablecido. Algunos ejemplos de datos continuos son:\n","\n","- La *altura de una persona* puede ser cualquier valor decimal comprendido entre 0 e $\\infty$.\n","- La *distancia entre dos ciudades* puede ser cualquier valor decimal comprendido entre 0 e $\\infty$.\n","- La *temperatura de una ciudad* puede ser cualquier valor decimal comprendido entre $-\\infty$ y $\\infty$.\n","\n","Los datos continuos son los más habituales dentro del ecosistema del *machine learning* por lo que el correcto tratamiento de estos es fundamental para alcanzar los resultados esperados. El principal problema de este tipo de datos es que no disponen de una escala homogénea, por lo que, cada dato, se mueve en un rango diferente al del resto, lo que dificulta enormemente el aprendizaje a partir de los mismos.\n","\n","Generalmente, a los datos continuos se les realiza un proceso de estandarización o normalización con el fin de acotarlos a un rango de valores que permita compararlos entre si independientemente de su naturaleza."]},{"cell_type":"markdown","metadata":{"id":"6NUh7lQUch0B"},"source":["## Estandarización\n","\n","La **estandarización** es el proceso a partir del cual un conjunto de datos que siguen una distribución normal, hecho que sucede con la mayoría de los datos empleados en *machine learning*, son transformados a una distribución normal con media 0 y desviación típica 1. Para ello, se realiza la siguiente operación:\n","\n","$x^\\prime_i = \\frac{x_i - \\mu}{\\sigma}$\n","\n","Donde $x_i$ es el dato que queremos estandarizar, $\\mu$ es el valor medio de todos los datos y $\\sigma$ es la desviación típica de todos los datos.\n","\n","Ilustremos esto con un ejemplo. Asumamos que tenemos la siguiente matriz de datos en la que las filas son las muestras y las columnas las características:"]},{"cell_type":"code","metadata":{"id":"-lWMigVYLYCp"},"source":["import numpy as np\n","\n","X = np.array([[ 1., -1.,  2.],\n","              [ 2.,  0.,  0.],\n","              [ 0.,  1., -1.]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3xqlsxkLeKY"},"source":["Podemos emplear la función [preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale) de `sklearn`para estandarizar las características (i.e. las columnas):"]},{"cell_type":"code","metadata":{"id":"5fHWL923XV9-"},"source":["import sklearn\n","from sklearn import preprocessing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pj3DmGlLovW","executionInfo":{"status":"ok","timestamp":1600939845365,"user_tz":-120,"elapsed":836,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"1db2fa1e-b254-48a4-fdab-4aefb0f567bc","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["X_scaled = sklearn.preprocessing.scale(X)\n","print(X_scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0.         -1.22474487  1.33630621]\n"," [ 1.22474487  0.         -0.26726124]\n"," [-1.22474487  1.22474487 -1.06904497]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5tjEPyoHMJyk"},"source":["Como vemos, los datos han sido transformados a unos nuevos estandarizados. Si analizamos la media y desviación típica de estos datos observamos lo siguiente:"]},{"cell_type":"code","metadata":{"id":"GbfCGTJCMTNx","executionInfo":{"status":"ok","timestamp":1600939863273,"user_tz":-120,"elapsed":831,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"899f5256-5eb8-4559-cd32-8e206ff65909","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_scaled.mean(axis=0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"AxSaGr4dMcrs","executionInfo":{"status":"ok","timestamp":1600939865509,"user_tz":-120,"elapsed":772,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"53cbfa53-96cc-40ae-b04d-47050cff6efe","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_scaled.std(axis=0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1.])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"9nU50J3MMeq7"},"source":["La media de cada característica ha sido centrada en el 0 y la desviación típica puesta en 1. Si comparamos esto con los datos sin estandarizar vemos la diferencia:"]},{"cell_type":"code","metadata":{"id":"sWVDnWKEQviO","executionInfo":{"status":"ok","timestamp":1600939873570,"user_tz":-120,"elapsed":915,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"aef153c5-15da-4257-f5f9-5a325643eec5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X.mean(axis=0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.        , 0.        , 0.33333333])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"3trg_H6cRFpS","executionInfo":{"status":"ok","timestamp":1600939874602,"user_tz":-120,"elapsed":580,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"67fdcb26-c07e-435d-829d-5be8242ee6af","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X.std(axis=0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.81649658, 0.81649658, 1.24721913])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"PyUhuEQkRv3n"},"source":["Podemos observar cómo se han modificado los datos para que todos ellos sigan una distribución normal de media 0 y desviación típica 1."]},{"cell_type":"markdown","metadata":{"id":"X6xDnRURdB0N"},"source":["Aunque, como hemos mencionado, la mayoría de los datos usados en *machine learning* siguen una distribución normal y, por tanto, pueden ser estandarizados, antes de aplicar este proceso debemos validar la normalidad de un conjunto de datos. Para ello debemos aplicar el test de Kolmogorov-Smirnov disponible en `scipy`:"]},{"cell_type":"code","metadata":{"id":"K1a189u-dgcJ","executionInfo":{"status":"ok","timestamp":1600940103331,"user_tz":-120,"elapsed":790,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"faae8d26-02e3-40b7-8926-c5a029648a6e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from scipy import stats\n","\n","x = np.linspace(-15, 15, 9)\n","stats.kstest(x, 'norm')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KstestResult(statistic=0.4443560271592436, pvalue=0.03885014270517116)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"zjfWfVyRdxR9","executionInfo":{"status":"ok","timestamp":1600940136140,"user_tz":-120,"elapsed":997,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"3fa2f1ff-bea7-48d6-b759-df2ba68de612","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["stats.kstest(stats.norm.rvs(size=1000), 'norm')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KstestResult(statistic=0.042559039297019485, pvalue=0.05190003788979243)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"ZAxFJcqNeJYf"},"source":["Observamos que, cuando la distribución de los datos es normal, el valor del atributo `statistic` devuelto por la función es cercano a 0."]},{"cell_type":"markdown","metadata":{"id":"DYNUp9KGeV5k"},"source":["No obstante, aunque sólo debe aplicarse estandarización con datos normales, en la mayoría de casos, no se comprueba la normalidad, se asume, y se estandariza el conjunto de datos."]},{"cell_type":"markdown","metadata":{"id":"O_nn6rd5Sa-F"},"source":["## Escalado\n","\n","Existe otra alternativa para la estandarización de las características que consiste en ajustarlas en un rango predefinido, generalmente en el rango $[0, 1]$. Usualmente se utiliza cuando se tienen datos con una desviación típica muy pequeña."]},{"cell_type":"markdown","metadata":{"id":"hhVHZjqnS4s0"},"source":["Para la realización de este escalado usaremos la función [preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler). Si queremos normalizar en la escala $[0, 1]$ usaremos:\n","\n"]},{"cell_type":"code","metadata":{"id":"dKIoh2YhTI-J","executionInfo":{"status":"ok","timestamp":1600940295901,"user_tz":-120,"elapsed":821,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"fedc6244-d81c-4c77-f052-19cf8235978c","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n","X_scaled = min_max_scaler.fit_transform(X)\n","print(X_scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.5        0.         1.        ]\n"," [1.         0.5        0.33333333]\n"," [0.         1.         0.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gdr2B_PaTtkx"},"source":["Si queremos emplear otro rango simplemente debemos indicar, mediante una dupla, la escala deseada en el constructor del objeto:"]},{"cell_type":"code","metadata":{"id":"bzm_IJa0T0Hn","executionInfo":{"status":"ok","timestamp":1600940301180,"user_tz":-120,"elapsed":1012,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgiZKcEyk_b-6E_dNg7_x20idZVEj0N7w-N6pwgBQ=s64","userId":"02003917424124170753"}},"outputId":"e5e233fe-4fc7-4ff4-a5f7-47a98ba79ef8","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["min_max_scaler = sklearn.preprocessing.MinMaxScaler((1,5)) # escala [1, 5]\n","X_scaled = min_max_scaler.fit_transform(X)\n","print(X_scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[3.         1.         5.        ]\n"," [5.         3.         2.33333333]\n"," [1.         5.         1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GLy9k4ToUZyK"},"source":["## Normalización\n","\n","Otra transformación habitual para este tipo de datos es la conocida como **normalización**. La normalización es el proceso de escalar cada muestra individual para que tengan la norma unitaria. Dicho de otro modo, si asumimos cada muestra como un vector *n*-dimensional (*n* es el número de características), mediante la normalización logramos que estos vectores tengan dimensión 1.\n","\n","Para ello, existen tres normas:\n","\n","- *L1*, se normaliza mediante la suma de los valores absolutos de sus componentes.\n","- *L2*, se normaliza mediante la raíz cuadrada de la suma de sus componentes al cuadrado.\n","- *max*, se normaliza mediante elemento mayor de sus componentes.\n","\n","Por ejemplo, si tenemos el vector $X = [-3, 4]$ obtendríamos:\n","\n","- *L1*: la norma se calcula como $|-3| + |4| = 7$ y el vector quedaría $X^\\prime = [-0.43, 0.57]$.\n","- *L2*: la norma se calcula como $\\sqrt{(-3)^2 + 4^2} = \\sqrt{9+16} = \\sqrt{25} = 5$ y el vector quedaría $X^\\prime = [-0.12, 0.16]$.\n","- *max*: la norma sería $4$ y el vector quedaría $X^\\prime = [-0.75, 1]$.\n","\n","La más utilizada es la norma L2 y suele aplicarse cuando el algoritmo seleccionado utiliza una forma cuadrática como, por ejemplo, el producto escalar, para calcular la similaridad entre cada par de muestras."]},{"cell_type":"markdown","metadata":{"id":"kPG5b-fFZ8VR"},"source":["Para la normalización utilizaremos [preprocessing.normalize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize):\n","\n"]},{"cell_type":"code","metadata":{"id":"ns94N_UgFkPg","executionInfo":{"status":"ok","timestamp":1564398387809,"user_tz":-120,"elapsed":551,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"outputId":"43124766-47f7-416e-ab16-f841df21f128","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["X_normalized_l1 = sklearn.preprocessing.normalize(X, norm='l1')\n","print(X_normalized_l1)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0.25 -0.25  0.5 ]\n"," [ 1.    0.    0.  ]\n"," [ 0.    0.5  -0.5 ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yTFOb2DSaQfJ","executionInfo":{"status":"ok","timestamp":1564398396839,"user_tz":-120,"elapsed":583,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"outputId":"3f0123ac-f139-4336-f3b7-c998428e1e2a","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["X_normalized_l2 = sklearn.preprocessing.normalize(X, norm='l2')\n","print(X_normalized_l2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0.40824829 -0.40824829  0.81649658]\n"," [ 1.          0.          0.        ]\n"," [ 0.          0.70710678 -0.70710678]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r61sJ0k7aTBl","executionInfo":{"status":"ok","timestamp":1564398409947,"user_tz":-120,"elapsed":579,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"outputId":"688f6b45-1504-407e-bf70-80fedef61a94","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["X_normalized_max = sklearn.preprocessing.normalize(X, norm='max')\n","print(X_normalized_max)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0.5 -0.5  1. ]\n"," [ 1.   0.   0. ]\n"," [ 0.   1.  -1. ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HXXG8zr1vfld"},"source":["<hr>\n","\n","Creado por **Fernando Ortega** (fernando.ortega@upm.es)\n","\n","<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"]}]}