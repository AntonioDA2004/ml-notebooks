{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Elastic-Net.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPQITfAKInIspnyub3HCjwy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VBeCYRGBQuI6"},"source":["# Elastic-Net\n","\n","El regresor denominado *Elastic-Net* combina en su función de coste las regularizaciones propuestas por los regresores *Ridge* (*$\\ell2$ regularization*) y *LASSO* (*$\\ell1$ regularization*). El peso de cada una de las regularizaciones es ponderado mediante un hiper-parámetro *r*.\n","\n","La función de coste asociada a *Elastic-Net* que queremos minimizar será:\n","\n","$$\\hat{y}_i = \\sum_{f=1}^F w_f \\cdot x_{i,f}$$\n","\n","$$\\min_w \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + r \\cdot \\alpha \\sum_{f=1}^F |w_f| + \\frac{1-r}{2} \\alpha \\sum_{f=1}^F w_f^2$$\n","\n","Donde $N$ es el número de muestras de nuestro conjunto de datos y $F$ es el número de *features* del mismo.\n","\n","Nótese que el modelo descrito dispone de dos hiper-parámetros que permiten ajustar la importancia de los coeficientes de regularización:\n","\n","- $\\alpha$ permite definir el peso de la regularización (tanto $\\ell1$ como $\\ell2$) en la función de coste para evitar el *overfitting*.\n","- $r$ permite controlar la importancia de la regularización $\\ell1$ frente a la regularización $\\ell2$. Valores cercanos a 0 darán más importancia a la segunda mientras que valores cercano a 1 darán más importancia a la primera."]},{"cell_type":"markdown","metadata":{"id":"SCRmKo--VYjb"},"source":["*Elastic-Net* se encuentra implementado en la clase [`sklearn.linear_model.ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) de la librería `sklearn`. Su constructor dispone principalmente  de dos parámetros que debemos definir:\n","\n","- `alpha` que representa el valor de $\\alpha$ explicado anteriormente.\n","- `l1_ratio` cuyo valor se corresponde con el parámetro $r$ explicado anteriormente.\n","\n","El siguiente ejemplo muestra la importancia de los parámetros sobre un conjunto de datos generado sintéticamente:"]},{"cell_type":"code","metadata":{"id":"qQnUMewwQsjK"},"source":["import numpy as np              \n","import matplotlib.pyplot as plt \n","from sklearn.linear_model import ElasticNet\n","\n","\n","fig, axs = plt.subplots(3, 3, figsize=(18,9))\n","plt.subplots_adjust(hspace=0.3)\n","\n","def plot(data2D, target1D, predict1D, row, column, title):\n","    axs[row,column].plot(data2D, target1D, 'y.', markersize=6,\n","                         label='Samples')\n","    axs[row,column].plot(data2D, predict1D, 'k-', label='Prediction')\n","    axs[row,column].legend()\n","    axs[row,column].set_title('Elastic Net, '+title)\n","    axs[row,column].grid()\n","    return\n","\n","N = 100  # number of samples                      \n","X = np.linspace(0,10,N)       \n","y = 0.8*X + np.random.randn(N)  \n","for i in range(1,30):\n","    y[-i]+=40-i   # inserting outliners\n","X = np.vstack([np.zeros(N), X]).T\n","\n","for l1_ratio, row in zip([0.001,0.5,1.0], [0,1,2]):\n","    for alpha, column in zip([0.001,8,80], [0,1,2]):\n","        elastic = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n","        elastic.fit(X, y)\n","        y_pred = elastic.predict(X)\n","        plot(X[:,1], y, y_pred, row, column, 'L1 ratio: '+str(l1_ratio)+', alpha: '+str(alpha))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uACkhfWrgFkC"},"source":["---\n","\n","Creado por **Fernando Ortega** (fernando.ortega@upm.es)\n","\n","<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"]}]}