{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Métricas de evaluación para regresión\n",
    "\n",
    "La forma más común de evaluar el ajuste global de un modelo lineal es por el valor $R^2$. $R^2$ es la proporción de la varianza explicada, es decir, la proporción de la varianza en los datos observados que es explicada por el modelo, o la reducción del error sobre el modelo nulo. El modelo nulo sólo predice la media de la respuesta observada, y por lo tanto tiene un *intercept* pero no una pendiente.\n",
    "\n",
    "$R^2$ está entre 0 y 1, y más alto es mejor porque significa que el modelo explica más varianza.\n",
    "\n",
    "Además de $R^2$ existen otras métricas para evaluar la calidad de los modelos de regresión. Las más utilizadas son las siguientes:\n",
    "\n",
    "* **Mean Absolute Error (MAE)** es la media de los valores absolutos de los errores\n",
    "$$\\frac{1}{n}\\sum^{n}_{i=1}\\left | y_i - \\widehat{y}_i  \\right |$$\n",
    "\n",
    "* **Mean Squared Error (MSE)** es la media de los cuadrados de los errores\n",
    "$$\\frac{1}{n}\\sum^{n}_{i=1}\\left ( y_i - \\widehat{y}_i  \\right )^2$$\n",
    "\n",
    "* **Root Mean Squared Error (RMSE)** es la raíz cuadrada de la media de los errores al cuadrado\n",
    "$$\\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}\\left ( y_i - \\widehat{y}_i  \\right )^2}$$\n",
    "\n",
    "Todas estas métricas están implementadas en [scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/classes.html#sklearn-metrics-metrics).\n",
    "\n",
    "El *MSE* es más popular que el *MAE* porque \"castiga\" los errores más grandes. Esto quiere decir que es una métrica más exigente con respecto a la calidad del modelo. Por otro lado, la *RMSE* es aún más popular que la *MSE* porque sus resultados son interpretables en unidades de la variable de salida.\n",
    "\n",
    "Observemos su funcionamiento sobre el conjunto de datos de las casas de California:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"QksAShlDCHCRYPxkfRQlDV",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"z7yhzBns8UtbW2AiDtVIBP"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "ridge = Ridge(alpha=1.0).fit(X, y)\n",
    "\n",
    "y_pred = ridge.predict(X)\n",
    "\n",
    "print(\"MAE: \", mean_absolute_error(y, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y, y_pred))\n",
    "print(\"RMSE: \", mean_squared_error(y, y_pred, squared=False))\n",
    "print(\"R2: \", ridge.score(X, y))"
   ],
   "execution_count":2,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"TTlvh0367wzbrUHrCtE5gS",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"dCIrvLjQanPkPFt0Hsq1Gi"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Observamos que el MAE es el error más interpretable, puesto de promedio nos equivocamos en $0.53 \\times 100.000 = 53.000$ dólares en el precio de una casa. El MSE no tiene un significado fácil de interpretar, pero el RMSE muestra valores similares al MAE, solo que, al ser más alto, denota que el error en las predicciones es dispar. Por último, el $R^2$ demuestra que se está explicando el 60\\% de la varianza."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"SA8E1DFTSe8dwZzrK6zNS8",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"NrnGHBU8xmU1PiiIDO50M4"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Evaluación justa de los modelos\n",
    "\n",
    "Hasta ahora hemos estado calculando las medidas de calidad de los modelos con el mismo conjunto de datos que se ha usado para su entrenamiento. Si bien evaluar los modelos de esta forma nos puede dar una aproximación de la dificultad que ha tenido el modelo para entrenarse, es una evaluación **nada justa** del modelo, puesto que estamos evaluando su rendimiento pidiendo que nos calcule la predicción de **los mismos datos** con los que ha realizado el ajuste. Por tanto, estamos confundiendo **rendimiento** con **overfitting**.\n",
    "\n",
    "Para realizar una evaluación más justa de cualquier modelo de *machine learning* se utiliza la división del conjunto de datos en dos conjuntos: uno para **entrenamiento** y otro para **test**.\n",
    "\n",
    "La idea básica es reservar un porcentaje de los datos de entrada para utilizarlos posteriormente en la fase de evaluación del modelo. Estos datos, al no participar en el entrenamiento de este, pueden considerarse como datos futuros. Por lo tanto, comprobar qué tal se comporta el modelo intentando predecir los datos de **test** es una forma justa de evaluar la capacidad de generalizar del modelo, lo que a fin de cuentas es la principal característica cuando se trata de *machine learning*.\n",
    "\n",
    "Un detalle importante es el mecanismo utilizado para realizar la división del conjunto de datos. Si se realiza *a mano* estamos inevitablemente introduciendo un sesgo en el proceso, ya que podría suceder que el subconjunto seleccionado no sea representativo del conjunto total. Por ello se suele dividir el conjunto de datos mediante un muestreo **aleatorio**.\n",
    "\n",
    "`sklearn` cuenta con una función para realizar la partición mediante muestreo aleatorio del conjunto de datos de entrada en dos subconjuntos, uno de entrenamiento y otro de test. La función en cuestión es `train_test_split`, y se encuentra en el módulo `model_selection`.\n",
    "\n",
    "Vamos a repetir la evaluación de las combinaciones de variables para el conjunto de datos del precio de las casas, aunque utilizando la división de los datos en entrenamiento y test:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"G5TFLfs9apAeK5JrKLizwM",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"TNTPOjmpNWAulG2h4NOXMN"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "ridge = Ridge(alpha=1.0).fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: \", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"R2: \", ridge.score(X_test, y_test))"
   ],
   "execution_count":3,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"e4TAVeUEQLrQWzn9Ni4cR1",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"pQEQasKKIa1LpFlIyWh2YS"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Cross-validation (validación cruzada)\n",
    "\n",
    "Aunque hemos dado un gran paso hacia una evaluación más justa de los modelos, todavía hay algunos detalles que se pueden mejorar. Y es que, si la separación del *dataset* en entrenamiento y test se realiza mediante un muestreo aleatorio, podría suceder que por casualidad todas las muestras que vayan al conjunto de test sean todas casas de 3 habitaciones, por poner un ejemplo. De esta forma se estaría introduciendo un sesgo en el proceso.\n",
    "\n",
    "Una forma de mitigar esto es realizar $K$ separaciones diferentes y aleatorias, calcular las medidas de calidad de cada una de estas separaciones y luego agruparlas con alguna función de agregación (media, mediana, ...). Este proceso se conoce como **K-fold cross-validation** y se puede considerar casi un estándar a la hora de evaluar el rendimiento de un modelo de aprendizaje computacional.\n",
    "\n",
    "La siguiente imagen muestra un proceso de 5-fold cross-validation, donde se observa que cada iteración usa unos conjuntos de entrenamiento y test distintos:\n",
    "\n",
    "![](https:\/\/i.imgur.com\/R6nj4E9.png)\n",
    "\n",
    "`sklearn` cuenta con herramientas para realizar validación cruzada a la hora de evaluar los modelos. A continuación vamos a realizar la evaluación del modelo que tiene en cuenta todas las variables de entrada siguiendo el enfoque de **validación cruzada**:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"i4RrI4QyNaqfQFupZ3GE7U",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"DYxDbwyGxxHYGan3h9fVsH"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "ridge = Ridge(alpha=1)"
   ],
   "execution_count":4,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"DUrU7rT7qi8fHeezXeHokA",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"OUif8RtThpiIguiRyre4xg"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')"
   ],
   "execution_count":5,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"i6lOssUCDm1wy8s7iLA4xf",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"doZdRy7aK7f1ZB5BL3vHQB"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Hay otras métricas interesantes, como por ejemplo el error máximo cometido en alguna de las predicciones, que nos da una medida de cómo de 'malo' es nuestro modelo en el peor de los casos:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"kyvLIA8Nvxx4Nr4IHJ1nwM",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"aRZgi6A8tHXRndPVUbyXc8"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cross_val_score(ridge, X, y, cv=5, scoring='max_error')"
   ],
   "execution_count":6,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"X20YwqN8ufvoaXXV9dLCx7",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"ko7cliT7Ifz9mA0E7eg7Od"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "O el error absoluto mediano, que es una métrica más robusta con respecto a las observaciones atípicas, también conocidas como *outliers*:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"SWZQJKQw3RF9UCyQqSAGv9",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"LTPjPxDFaZgovlI78tIIUg"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cross_val_score(ridge, X, y, cv=5, scoring='neg_median_absolute_error')"
   ],
   "execution_count":7,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"XwdveQKg6EgBCMho7cozgF",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"5E1dCHmvzh5PJLWwwC0PwJ"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Para conjunto de datos muy reducidos, podemos usar *leave one out*, realiza tanto entrenamientos como muestras tenga el conjunto de datos excluyendo, en cada uno de ellos, una muestra que luego será evaluada:"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"0nZgNz2B2f3WU37KtPi6D6",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"SgIUuMKd0kF9AtlAzYLWLq"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(ridge, X, y, cv=loo, scoring='neg_mean_squared_error')\n",
    "scores.mean()"
   ],
   "execution_count":9,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"ByS02Mg0UKyNAtatRZl3ui",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"XLIK7Cs5lRhewK4gyE7Ipi"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "---\n",
    "\n",
    "Creado por **Raúl Lara** (raul.lara@upm.es) y **Fernando Ortega** (fernando.ortega@upm.es)\n",
    "\n",
    "<img src=\"https:\/\/licensebuttons.net\/l\/by-nc-sa\/3.0\/88x31.png\">"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"EUAetiPv1qI37ZpucRMPq3",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"5Te2lSzK9QVbYowAb8n1C8"
     }
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[],
   "report_row_ids":[],
   "report_tabs":[
    {
     "id":"n0JA0xIhDw2M9yvYtXbTDe",
     "name":"Report tab",
     "rows":[
      "z7yhzBns8UtbW2AiDtVIBP",
      "dCIrvLjQanPkPFt0Hsq1Gi",
      "NrnGHBU8xmU1PiiIDO50M4",
      "TNTPOjmpNWAulG2h4NOXMN",
      "pQEQasKKIa1LpFlIyWh2YS",
      "DYxDbwyGxxHYGan3h9fVsH",
      "OUif8RtThpiIguiRyre4xg",
      "doZdRy7aK7f1ZB5BL3vHQB",
      "aRZgi6A8tHXRndPVUbyXc8",
      "ko7cliT7Ifz9mA0E7eg7Od",
      "LTPjPxDFaZgovlI78tIIUg",
      "5E1dCHmvzh5PJLWwwC0PwJ",
      "SgIUuMKd0kF9AtlAzYLWLq",
      "XLIK7Cs5lRhewK4gyE7Ipi",
      "5Te2lSzK9QVbYowAb8n1C8"
     ]
    }
   ],
   "version":4
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}